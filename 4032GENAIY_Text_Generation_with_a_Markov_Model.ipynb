{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michaelbejusca/TextGenerator_MarkovModel/blob/main/4032GENAIY_Text_Generation_with_a_Markov_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generation with a Markov Model\n",
        "\n",
        "Using Markov models/chains is one of the oldest methods for generating text.\n",
        "\n",
        "This notebook demonstrates a very simple way to produce a Markov Chain from some source text, based on constructing character-level n-grams, and then use this to generate some new text, hopefully in the same style."
      ],
      "metadata": {
        "id": "VFOtgpCVZH1q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Seeu1on4ZGqJ"
      },
      "outputs": [],
      "source": [
        "input_text = \"Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, `and what is the use of a book,' thought Alice `without pictures or conversation?' So she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her. There was nothing so very remarkable in that; nor did Alice think it so very much out of the way to hear the Rabbit say to itself, `Oh dear! Oh dear! I shall be late!' (when she thought it over afterwards, it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but when the Rabbit actually took a watch out of its waistcoat-pocket, and looked at it, and then hurried on, Alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and fortunately was just in time to see it pop down a large rabbit-hole under the hedge.\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can display an extract of the input text and format it for the screen using `textwrap`:"
      ],
      "metadata": {
        "id": "zR-MEhSDvvDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "print(textwrap.fill(input_text, 120))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_Eq1YIJZ2X2",
        "outputId": "7fcd720b-dc58-4098-fe90-018378194444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice\n",
            "she had peeped into the book her sister was reading, but it had no pictures or conversations in it, `and what is the use\n",
            "of a book,' thought Alice `without pictures or conversation?' So she was considering in her own mind (as well as she\n",
            "could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be\n",
            "worth the trouble of getting up and picking the daisies, when suddenly a White Rabbit with pink eyes ran close by her.\n",
            "There was nothing so very remarkable in that; nor did Alice think it so very much out of the way to hear the Rabbit say\n",
            "to itself, `Oh dear! Oh dear! I shall be late!' (when she thought it over afterwards, it occurred to her that she ought\n",
            "to have wondered at this, but at the time it all seemed quite natural); but when the Rabbit actually took a watch out of\n",
            "its waistcoat-pocket, and looked at it, and then hurried on, Alice started to her feet, for it flashed across her mind\n",
            "that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with\n",
            "curiosity, she ran across the field after it, and fortunately was just in time to see it pop down a large rabbit-hole\n",
            "under the hedge.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is a Markov Chain?\n",
        "A Markov Chain is a stochastic process that is \"memory-less\". That is, the probability of *future* states are not dependent upon the states that preceded the *present* state.\n",
        "\n",
        "The general property of a Markov Chain is:\n",
        "\n",
        "\\begin{equation}\n",
        "P(X_{n+1} = j \\mid X_0 = i_0, X_1 = i_1, \\dots X_{n-1} = i_{n-1}, X_n = i) = P(X_{n+1} = j \\mid X_n = i)\n",
        "\\end{equation}"
      ],
      "metadata": {
        "id": "2sEYKJxcaOSN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Create a Dictionary to Capture Transition Probabilities\n",
        "\n",
        "To implement a Markov chain, we are going to create a **dictionary of n-grams**. The n-grams in this model will be based on characters, not words, in the input text.\n",
        "\n",
        "For the moment, we will construct a Markov chain using n-grams or length 3, or trigrams. But the order of the n-grams is a parameter that can be tuned later get better (or more interesting) generated texts.\n",
        "\n",
        "The first step is to divide the text into n-grams. For this dictionary, the n-grams will be the keys and each instance of a character that follows a given n-gram will be added to an array as the value for the key.\n",
        "\n",
        "This means that if a combination of n-gram and a specific character appear twice in the input text, then the n-gram's array will contain the same character twice. This captures the frequency with which a character follows a n-gram, but perhaps not in the most elegant, or space-efficient, way."
      ],
      "metadata": {
        "id": "7g-lauqZa0hR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def markov_process(seq, order): #function creating a dictionary\n",
        "  markov_dict = {} #empty dictionary to store the model\n",
        "  seq = list(seq[:]) + [None] # convert the text into list of characters\n",
        "  # order is the number of grams we are using.\n",
        "  for i in range(len(seq) - order):\n",
        "      gram = tuple(seq[i:i+order])\n",
        "      if gram not in markov_dict:\n",
        "          markov_dict[gram] = []\n",
        "      markov_dict[gram].append(seq[i+order])\n",
        "  return markov_dict"
      ],
      "metadata": {
        "id": "cXN9bEfteulX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naturally, we can inspect the output of the dictionary:"
      ],
      "metadata": {
        "id": "ynkGlzRxySJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "markov_dict = markov_process(input_text, 3)\n",
        "print(textwrap.fill(str(markov_dict)[:960], 120))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md3LdRxlfKhc",
        "outputId": "44f6fe45-b568-4935-e8c3-52321d04f7d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{('A', 'l', 'i'): ['c', 'c', 'c', 'c'], ('l', 'i', 'c'): ['e', 'e', 'e', 'e'], ('i', 'c', 'e'): [' ', ' ', ' ', ' ', '\n",
            "'], ('c', 'e', ' '): ['w', 'o', 's', '`', 't', 's'], ('e', ' ', 'w'): ['a', 'a', 'o', 'a', 'a', 'o'], (' ', 'w', 'a'):\n",
            "['s', 's', 's', 's', 'y', 't', 'i', 'i', 't', 's'], ('w', 'a', 's'): [' ', ' ', ' ', ' ', ' '], ('a', 's', ' '): ['b',\n",
            "'r', 'c', 'w', 's', 'n', 'j'], ('s', ' ', 'b'): ['e'], (' ', 'b', 'e'): ['g', ' ', ' ', 'f'], ('b', 'e', 'g'): ['i'],\n",
            "('e', 'g', 'i'): ['n'], ('g', 'i', 'n'): ['n'], ('i', 'n', 'n'): ['i'], ('n', 'n', 'i'): ['n'], ('n', 'i', 'n'): ['g',\n",
            "'g'], ('i', 'n', 'g'): [' ', ' ', ' ', ' ', ',', ' ', ' ', ' ', ' ', ' ', ' '], ('n', 'g', ' '): ['t', 'b', 'n', 't',\n",
            "'i', 'a', 'u', 't', 's', 'w'], ('g', ' ', 't'): ['o', 'o', 'h'], (' ', 't', 'o'): [' ', ' ', ' ', ' ', ' ', ' ', 'o', '\n",
            "', ' ', ' '], ('t', 'o', ' '): ['g', 'd', 't', 'h', 'i', 'h', 'h', 'h', 't', 's'], ('o', ' ', 'g'): ['e'], (' ', 'g',\n",
            "'e'): ['t'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Generate Text\n",
        "\n",
        "After defining the states of the Markov chain the n-gram model can be used generate text. By default the starting point for generation is the first n-gram in the text. This is asigned to `currentgram` then with the function `random.choice()` we pick the next character to add to the output (`output`) from the array associated with `currentgram` in the dictionary.\n",
        "\n",
        "The default length of the generated text is arbitrarily set to 500 but this can be changed by supplying a value for `length`."
      ],
      "metadata": {
        "id": "fKS3mI5wfa0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def markov_gen(seq, order, length=500, start=None):\n",
        "    markov_dict = markov_process(seq, order)\n",
        "    if start == None or len(start) != order or not (tuple(start) in markov_dict.keys()):\n",
        "      currentgram = tuple(seq[:order])\n",
        "    else:\n",
        "      currentgram = tuple(start)\n",
        "    output = list(currentgram)\n",
        "    for i in range(length-order):\n",
        "        next = random.choice(markov_dict[currentgram])\n",
        "        if next == None:\n",
        "          break;\n",
        "        else:\n",
        "          output.append(next)\n",
        "        currentgram = tuple(output[-order:])\n",
        "    return output"
      ],
      "metadata": {
        "id": "bDx2iSi1ghH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_text = ''.join(markov_gen(input_text, 3))\n",
        "print(textwrap.fill(output_text, 120))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hPgTHt-hM9X",
        "outputId": "160c3bd9-5068-4292-cced-17e5ec0ebdc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alice seen suddenly a White nate!' (when the undering to that to hered at so very time tooked after a White Rabbit-hole\n",
            "under after sistcoat-pocket, fore stupid), when her beginning by her the had neversations in time tired of the hot day\n",
            "much out at to down mind to her befortunately was remarkable of it had peeped quite Rabbit of it whethe daisies, it all\n",
            "seemed afterwards, when suddenly to do: on, Alice was nothing by her the that to take ought in the pleasures reading\n",
            "nothis, but of sitting n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `markov_gen()` allows a starting n-gram to be provided as a parameter. The provided n-gram must be of the same order as the n-grams constructed in the Markov chain and it must actually appear in the text. Otherwise the n-gram will be ignored and the function will return text generated using the first n-gram in the text."
      ],
      "metadata": {
        "id": "eaaBbBegtTcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_text = ''.join(markov_gen(input_text, 3, 1000, \"Whi\"))\n",
        "print(textwrap.fill(output_text, 120))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX4aS5_kpdwX",
        "outputId": "5032365c-d388-49ff-f3e2-af3e53c198c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "White natural); but of sistcoat-pocket, and peeped to do: on the field at thered in tired at so versation?' So seemed on\n",
            "thing a watch ought Alice wonder a daistcoat-pocket, and the there waisy-chain tired in would, fore of the Rabbit\n",
            "picking by hed on thought Alice the thout pictuall seemed think its was rabbit over waisies, but with curred in the her\n",
            "own mind look her. There seemed quite Rabbit-hole it of sisterwards, when her mind started on, Alice time it whethered\n",
            "in the considering nothing to her the the had nothing nothis, what so versation?' So she time the thought the daistcoat-\n",
            "pocket, or it so ver a watch out pink eyes ran close out of a was remarkable out of it of the day took her a day to get\n",
            "very making up and (as she book a book,' thought to down actures remarkable ought it pop do: on, Alice way making nor\n",
            "cons in time thought Alice ought Alice out of made her it, and started of that to getting to here seemed quite Rabbit\n",
            "with picking then hurried on, Alice `withe book,'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kafkanstein\n",
        "\n",
        "In this section we're going to explore how we can generate original text using a Markov chain by combining data sources. This exercise is inspired by the [Kafgenstein example](https://rednoise.org/rita/examples/p5/Kafgenstein/) developed for the RiTa library for Java/Processing and Javascript.\n",
        "\n",
        "## Instructions\n",
        "\n",
        "For this exercise, we will upload files to the Colab runtime.\n",
        "\n",
        "> *Note that these files will be deleted when the runtime closes, either because the window is closed intentionally or due to inactivity. If this happens, you will need to reupload the files.*\n",
        "\n",
        "Start by downloading the following files to your computer:\n",
        "\n",
        "- [kafka.txt](https://rednoise.org/rita/examples/data/kafka.txt)\n",
        "- [wittgenstein.txt](https://rednoise.org/rita/examples/data/wittgenstein.txt)\n",
        "\n",
        "Next, upload these files to the Colab runtime: open the files area in the left sidebar on the left by clicking on the folder icon. Then upload the files by either (1) dragging and dropping the files from your computer into the Colab files area; or (2) clicking on the document icon to open a file dialog and select the files on your computer to upload.\n",
        "\n",
        "We can now load the contents of these files into variables:"
      ],
      "metadata": {
        "id": "FhXjxJpJhKcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kafka_file = open(\"/content/kafka.txt\", 'r')\n",
        "kafka_text = kafka_file.read()\n",
        "# Print a short extract from the start of the file\n",
        "print(textwrap.fill(kafka_text[:960], 120))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYxKniLckTWj",
        "outputId": "9672bbe9-73a4-4e98-c465-3b06ab14e554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed into a horrible\n",
            "vermin. He lay on his armour-like back, and if he lifted his head a little he could see his brown belly, slightly domed\n",
            "and divided by arches into stiff sections. The bedding was hardly able to cover it and seemed ready to slide off any\n",
            "moment. His many legs, pitifully thin compared with the size of the rest of him, waved about helplessly as he looked.\n",
            "\"What's happened to me?\" he thought. It wasn't a dream. His room, a proper human room although a little too small, lay\n",
            "peacefully between its four familiar walls. A collection of textile samples lay spread out on the table - Samsa was a\n",
            "travelling salesman - and above it there hung a picture that he had recently cut out of an illustrated magazine and\n",
            "housed in a nice, gilded frame. It showed a lady fitted out with a fur hat and fur boa who sat upright, raising a heavy\n",
            "fur muff that cov\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wittgenstein_file = open(\"/content/wittgenstein.txt\", 'r')\n",
        "wittgenstein_text = wittgenstein_file.read()\n",
        "# Print a short extract from the start of the file\n",
        "print(textwrap.fill(wittgenstein_text[:960], 120))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCEFJIkbltGp",
        "outputId": "2ce9893d-641b-4df8-f91c-427b75863c49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perhaps this book will be understood only by someone who has himself already had the thoughts that are expressed in it--\n",
            "or at least similar thoughts.--So it is not a textbook.--Its purpose would be achieved if it gave pleasure to one person\n",
            "who read and understood it.  The book deals with the problems of philosophy, and shows, I believe, that the reason why\n",
            "these problems are posed is that the logic of our language is misunderstood. The whole sense of the book might be summed\n",
            "up the following words: what can be said at all can be said clearly, and what we cannot talk about we must pass over in\n",
            "silence.  Thus the aim of the book is to draw a limit to thought, or rather--not to thought, but to the expression of\n",
            "thoughts: for in order to be able to draw a limit to thought, we should have to find both sides of the limit thinkable\n",
            "i.e. we should have to be able to think what cannot be thought.  It will therefore only be in language that the limit\n",
            "can\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now generate a new text by supplying the `markov_gen()` function with a concatenation of the source texts. If we don't supply a starting n-gram (or one that is not of the required order) then the function will start with the first n-gram in the text, which will mean that it will start in the style of the first text used for the input, in the example here, the text from Kafka:"
      ],
      "metadata": {
        "id": "mdJl0bWtn8xH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kafkanstein_input = kafka_text + wittgenstein_text\n",
        "kafkanstein_output = ''.join(markov_gen(kafkanstein_input, 10, 960))\n",
        "print(textwrap.fill(kafkanstein_output, 120))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhwztHWtmwhI",
        "outputId": "6ded41bb-081b-441f-9831-9e9abaf97fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One morning, and it was out of the question whether I can get into the bedroom opened and Mr. Samsa appeared with these\n",
            "apparently primitive ideas both the concept of a function cannot be said: it makes itself manifest. The world is a\n",
            "metaphysical subject, or rather of showing that it is important but it is always a complex of objects could\n",
            "corresponding to the evening she would not be the most sensible thing to do the job himself.  And without looking up\n",
            "from what they signify two different resolution every time that his powerful chest shook.  So Gregor did not understands\n",
            "propositions--the axioms of mechanics, for example, the propositions by combining them so as to form proposition. It\n",
            "would require a justification, but I will work my way out of its primitive propositions: tautology and contradiction's\n",
            "impossible, impossible to infer the existence and non-existence of an internal relation', 'internal relations.  Reality\n",
            "is limited by the two w\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we supply a valid starting n-gram, we can have a bit more control over the starting text:"
      ],
      "metadata": {
        "id": "XuZpw0eLsCVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kafkanstein_output = ''.join(markov_gen(kafkanstein_input, 10, 960, \"philosophy\"))\n",
        "print(textwrap.fill(kafkanstein_output, 120))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4x7js9sGsLCQ",
        "outputId": "d7fc8c60-0466-4a45-acc7-8cffdf2321ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "philosophy of psychology. Does not my study of thoughts: for in order to signify something to show the logic of our\n",
            "language. Proposition, then we have determinate relations obtain: rather, that characterizes its sense with reality, in\n",
            "order that something similar. No-one drank very much. Gregor only remained from his business considerate as he could,\n",
            "but, unfortunately, to put Gregor's sister also had to help too - he could watch the family was totally by surprise, no-\n",
            "one was ever ill but that was not clear whether its meaning only in so far as a proposition. The negating propositions\n",
            "of logic be irrefutable, but obvious, just as, for instance by writing 'fxg'--that would exchange a tired grin. With a\n",
            "kind of attack. Instead of, 'This proposition contradict one another like the soughing of the propositions of logic.The\n",
            "truth of a propositions that such internal relation'. I introduce these expressions have the answers to question to\n",
            "leave him no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating text using word n-grams\n",
        "\n",
        "The `markov_process()` and `markov_gen()` functions can handle general sequences, not just strings. So if we process the text files to break them down into sequences of words, rather than characters, we can build word-based n-gram models and generate text using whole words. In general, this means that we need longer pieces of text to have enough variety, but the Kafka and Wittgenstein texts will suffice.\n",
        "\n",
        "To generate the word sequences we just need to split the string. The simplest way to do this is by split on space `' '` characters:"
      ],
      "metadata": {
        "id": "K3W7yG4tKooe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kafka_words = kafka_text.split(' ')"
      ],
      "metadata": {
        "id": "cKcMjSQhLdfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then generate new text from this sequence, we simply need to remember to join the result using a space character to get back to something like the source text:"
      ],
      "metadata": {
        "id": "3yq6DvlyLvdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kafka_output = ' '.join(markov_gen(kafka_words, 3, 100))\n",
        "print(textwrap.fill(kafka_output, 120))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OJ5IShdL7X6",
        "outputId": "50b52aea-ebe8-4567-ec05-aaafa4d1c1b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed when Gregor came back\n",
            "from his business trips, who would receive him sitting in the armchair in his nightgown when he came in from the hall,\n",
            "could see straight away that Gregor had been bringing home every month, keeping only a little for himself, so that that,\n",
            "too, had been accumulating. Behind the door, Gregor nodded with enthusiasm in his pleasure at this unexpected thrift and\n",
            "caution. He could actually have used this surplus money to reduce his father's debt to his boss, and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also still supply a starting, but we must remember to split any string into a sequence:"
      ],
      "metadata": {
        "id": "H-LVvALwMbpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kafka_output = ' '.join(markov_gen(kafka_words, 3, 100, \"Samsa woke from\".split()))\n",
        "print(textwrap.fill(kafka_output, 120))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aX5YhQkMpK8",
        "outputId": "caaac872-f919-4b2c-c39a-a8ffd068e2f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samsa woke from troubled dreams, he found himself transformed in his bed when Gregor came back from his business trips,\n",
            "who would receive him sitting in the armchair in his nightgown when he came in from the street towards the stairway, the\n",
            "curtains flew up, the newspapers on the table at home for the benefit of his astonished and delighted family. They had\n",
            "been good times and they had never asked each other about their work but all three had jobs which were very good and\n",
            "held particularly good promise for the future. Gregor, though, did think about the future.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimenting with the model\n",
        "\n",
        "Here are some ideas for experimenting with the Markov chain model developed here:\n",
        "\n",
        "- Experiment with the value for `order` to see how this changes the quality of the text produced for both character-based generation and word-based generation\n",
        "- Experiment with different input texts by uploading them to your runtime and then using them to generate new texts\n",
        "- Experiment with the length of the input text and how this impacts the diversity of output texts\n",
        "- Experiment with combining different texts together to form interesting mixtures\n",
        "- Experiment with more structured forms of text (e.g. poetry), or data files and comment on the success of the markov model to generate valid forms of these files\n",
        "\n",
        "## Tutorial Assignment\n",
        "\n",
        "Attempt at least 2 of the above suggestions to experiment with the model, or try some experiments of your own.\n",
        "\n",
        "Report on your experiments by submitting a notebook with the code for your experiments and comments on the things that you tried, what worked better than expected, what worked worse.\n",
        "\n",
        "Include in your submission any text files that your notebook relies on."
      ],
      "metadata": {
        "id": "itxCyfS7uro5"
      }
    }
  ]
}